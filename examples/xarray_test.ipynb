{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xarray_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNjg69+jl0fLESPGSM5Ma/I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cosunae/postproc_pt1/blob/main/examples/xarray_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPuMFTPwH8wt"
      },
      "source": [
        "\n",
        "# This notebook demonstrates how to add metadata and units consistency to xarray fields loaded from grid using cfgrib (https://github.com/ecmwf/cfgrib)\n",
        "\n",
        "This is useful for dimensional analysis and physical type correctness of computations in post-processing of NWP simulations\n",
        "https://arxiv.org/pdf/1807.07643.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5yJi9ixHrH2"
      },
      "source": [
        "First we need to setup the installation of cfgrib for loading grib files into xarray datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-zk2x50Dou7"
      },
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!conda install -c conda-forge cfgrib\n",
        "!python -m cfgrib selfcheck"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXUU7l5SJavJ"
      },
      "source": [
        "Download a sample grib file and small dataset classes that add pint units to xarray arrays. You should introduce the github token in order to clone the private repos:\n",
        "(https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGJdFfCapkuy"
      },
      "source": [
        "from getpass import getpass\n",
        "secret = getpass('Enter your github token value: ')\n",
        "import subprocess\n",
        "!rm -rf grib_files\n",
        "subprocess.run(['git', 'clone', 'https://'+secret+'@github.com/cosunae/grib_files.git'], check=True)\n",
        "!rm -rf postproc_pt1\n",
        "subprocess.run(['git', 'clone', 'https://'+secret+'@github.com/cosunae/postproc_pt1'], check=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBC4TlInGURj"
      },
      "source": [
        "!pip install postproc_pt1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dwZHDsrETKU"
      },
      "source": [
        "!python -m cfgrib selfcheck"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_T5Xp2hCe1I"
      },
      "source": [
        "from dataset import open_datasets\n",
        "\n",
        "dss = open_datasets('grib_files/cosmo-eu/lfff00000000_2014010400.gb2', engine='cfgrib', backend_kwargs={'filter_by_keys': {'typeOfLevel': 'generalVerticalLayer'}})\n",
        "print(dss[0])\n",
        "\n",
        "#q+QI\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjZwoEnnJ7Ev"
      },
      "source": [
        "Since there u and v are staggered fields (i.e. have different lon,lat coordinates), not all fields can be inserted into the same hypercube. Therefore 3 different datasets are generated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ_a9Hh8KFoT"
      },
      "source": [
        "mass_ds = dss[0]\n",
        "u_ds = dss[1]\n",
        "v_ds = dss[2]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDAerIQEKWY0"
      },
      "source": [
        "Inspect the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXSWLij7KYZ3"
      },
      "source": [
        "mass_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HxZbfEzKJ1x"
      },
      "source": [
        "Unpack the individual fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzy43gLdKNrl"
      },
      "source": [
        "t = mass_ds['t']\n",
        "q = mass_ds['q']\n",
        "QI = mass_ds['QI']\n",
        "pres = mass_ds['pres']\n",
        "u = u_ds['u']\n",
        "v = v_ds['v']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOa-sRO6Lnv3"
      },
      "source": [
        "import xarray as xr\n",
        "xr.set_options(keep_attrs = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz71stBxLHAN"
      },
      "source": [
        "# Following are compatible since dimensionless\n",
        "QQ = q+QI*0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCMHF9VDKhhe"
      },
      "source": [
        "# exception trigger due to incompatibility of dimensions\n",
        "try:\n",
        "    f = t+q\n",
        "except RuntimeError as e:\n",
        "    print(\"Testing error (as it should be)\",e)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nNzQVXrTuaI"
      },
      "source": [
        "# compute T at half levels, and check it preserves metadata and units \n",
        "def half_levels(f):\n",
        "  cf = f.cumsum(dim='generalVerticalLayer')\n",
        "  return (ct[2:] - ct[:-2])/float(2)\n",
        "\n",
        "t_half = half_levels(t)\n",
        "\n",
        "# Add t0\n",
        "t_half = t_half+t0\n",
        "\n",
        "# consistency check\n",
        "try: \n",
        "    f = t_half + q\n",
        "except RuntimeError as e:\n",
        "    print(\"Testing error (as it should be)\",e)\n",
        "\n",
        "# U & V are compatible. They both are defined in the same indexing x,y although have different lon,lat coordinates\n",
        "(u+v).isel(generalVerticalLayer=0).plot()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}